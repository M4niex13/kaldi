## 2、语音识别
### 语音识别框架
语料库➡️语音短时信号提取➡️语音识别声学参数➡️语音识别声学模型➡️语音识别语言模型➡️文字

#### Mel频率倒谱特征参数(MFCC)
Mel频率倒谱参数利用了听觉原理和倒谱的解相关特性，被证明是在语音识别任务中应用最成功的特征描述之一。

  `Mel(f)= 2595*log10(1+f/700)`
## HMM
http://www.cnblogs.com/skyme/p/4651331.html
### Viterbi algorithm
HMM（隐马尔可夫模型）是用来描述隐含未知参数的统计模型，举一个经典的例子：一个东京的朋友每天根据天气{下雨，天晴}决定当天的活动{公园散步,购物,清理房间}中的一种，我每天只能在twitter上看到她发的推“啊，我前天公园散步、昨天购物、今天清理房间了！”，那么我可以根据她发的推特推断东京这三天的天气。在这个例子里，显状态是活动，隐状态是天气。

任何一个HMM都可以通过下列五元组来描述：

    :param obs:可观测序列状态O
    :param states:隐状态S
    :param start_p:初始概率矩阵（隐状态）π
    :param trans_p:转移概率矩阵（隐状态）A
    :param emit_p: 发射概率 （隐状态表现为显状态的概率）(观测状态转移概率矩阵)B
HMM在实际应用中主要用来解决3类问题。

     1. 评估问题。

   即给定观测序列 O=O1O2O3…Ot和模型参数λ=(A,B,π)，怎样有效计算这一观测序列出现的概率

     2. 解码问题。

   即给定观测序列 O=O1O2O3…Ot和模型参数λ=(A,B,π)，怎样寻找满足这种观察序列意义上最优的隐含状态序列S。（根据几天的出行地点，推出几天的天气序列）

     3. 学习问题。

   即HMM的模型参数λ=(A,B,π)未知，如何求出这3个参数以使观测序列O=O1O2O3…Ot的概率尽可能的大。
   
   
   ### 服务器配置
   CPU用于解码，内存共用，解码时加载wfst很占内存。
   
   GPU，卡多一些做实验快。没有GPU需要设置配置。
   
   对于thchs30语料库，32G内存，有GPU，100G硬盘空间，就够了。但对于将来还会有更大的数据，大型实验，就不够了。

