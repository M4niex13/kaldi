## 知乎live 语音识别的前世今生
应用场景，做输入法，输入一段话，变成文字，智能地往里面加标点符号。
### 特征提取
一帧frame信号，通常20-50ms（2-3个周期，人说话频率100Hz），一个音素之内。
音素：音标的一个音，比如ei、si等

孤立词识别
对每一帧（有用信息：音色（包络））进行**傅立叶变换**  ➡️**三角滤波**得到filterbank output，基本可以作为特征了➡️**取对数log、离散余弦变换DCT**
压缩成更小的规模，13个采样点表示40个点的信息➡️**MFCC**语音的表示方式。

即一帧信息，转换成一个13维的向量。

MFCC序列是最常用的特征。主要描述频谱包络。
改进：一阶二阶差分，相邻两帧做差，得到上下文关系；各种归一化

怎样计算两个特征序列的距离?
### 动态弯算法 DTW
 - 让待识别语音中的每一帧与模板中最相似的一帧匹配（模板，比如一个yes、no语音，待识别语音去匹配）
 - 但要保持顺序
 - 动态规划算法
 - 总距离为各帧的欧氏距离之和


### GMM (高斯混合模型)
每次说yes可能是不一样的，所以要多录几次yes，如果每个词有多个模板，但总不能每个模板都去和待识别语音比较，最后取一个最好的吧，所以怎么办?
答：把模板压缩成模型。把每个模板切成5段，比如把其中一个模板当成待识别语音，和上下两个模板匹配，匹配的结果是吧某些向量放在同一个阶段，
把每个阶段的向量汇总起来。

五个阶段（五个状态）

简略的表示这些向量：用高斯混合模型来拟合这些向量（13维空间的点）用模型来拟合在高维空间分布的情况，哪些多，哪些少。

##### 训练模型
 - 把模板切分成多个段落(怎么切?)
 - 用高斯分布的叠加拟合每段中特征向量的分布。对任一特征向量，可给出概率密度，用概率密度代替向量间的欧式距离。
##### 如何用模型识别未知语音?
 - 用“动态弯”算法对齐待识别语音与模型。
   - 用GMM概率密度代替特征向量间的欧氏距离；
   - 相乘得到 P(待识别语音|模型)（这里隐含了一个独立性假设）
 - 取概率最大的模型为识别结果
 
 ### HMM (隐马尔可夫模型)
