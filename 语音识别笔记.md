## 知乎live 语音识别的前世今生
应用场景，做输入法，输入一段话，变成文字，智能地往里面加标点符号。
### 特征提取
一帧frame信号，通常20-50ms（2-3个周期，人说话频率100Hz），一个音素之内。
音素：音标的一个音，比如ei、si等

孤立词识别
对每一帧（有用信息：音色（包络））进行**傅立叶变换**  ➡️**三角滤波**得到filterbank output，基本可以作为特征了➡️**取对数log、离散余弦变换DCT**
压缩成更小的规模，13个采样点表示40个点的信息➡️**MFCC**语音的表示方式。

即一帧信息，转换成一个13维的向量。

MFCC序列是最常用的特征。主要描述频谱包络。
改进：一阶二阶差分，相邻两帧做差，得到上下文关系；各种归一化

怎样计算两个特征序列的距离?
### 动态弯算法 DTW
 - 让待识别语音中的每一帧与模板中最相似的一帧匹配（模板，比如一个yes、no语音，待识别语音去匹配）
 - 但要保持顺序
 - 动态规划算法
 - 总距离为各帧的欧氏距离之和


### GMM (高斯混合模型)
每次说yes可能是不一样的，所以要多录几次yes，如果每个词有多个模板，但总不能每个模板都去和待识别语音比较，最后取一个最好的吧，所以怎么办?
答：把模板压缩成模型。把每个模板切成5段，比如把其中一个模板当成待识别语音，和上下两个模板匹配，匹配的结果是吧某些向量放在同一个阶段，
把每个阶段的向量汇总起来。

五个阶段（五个状态）

简略的表示这些向量：用高斯混合模型来拟合这些向量（13维空间的点）用模型来拟合在高维空间分布的情况，哪些多，哪些少。

##### 训练模型
 - 把模板切分成多个段落(怎么切?)
 - 用高斯分布的叠加拟合每段中特征向量的分布。对任一特征向量，可给出概率密度，用概率密度代替向量间的欧式距离。
##### 如何用模型识别未知语音?
 - 用“动态弯”算法对齐待识别语音与模型。
   - 用GMM概率密度代替特征向量间的欧氏距离；
   - 相乘得到 P(待识别语音|模型)（这里隐含了一个独立性假设）
 - 取概率最大的模型为识别结果
 
 ### HMM (隐马尔可夫模型)

### 语言模型
n-gram，比如Bigram（2-gram）、trigram：每个词只与前n-1个词有关。

- Bigram是马尔可夫模型：
  - 下一个词只与当前词有关；**马尔可夫**：在HMM中，也说HMM是马尔可夫模型，是指下一个状态和观测向量只与当前状态有关。
  - 模型是遍历的，不是单向的。
- 可与单词的声学模型复合
  - 得到一门语言的HMM。
 
把语言模型看成一个马尔可夫模型的好处：可以与单词的声学模型复合。 比如PPT上，皮的三个状态，是皮的声学模型，声学模型和语言模型复合后，就得到一个大的复合模型。大的转移概率中，留在自身0.6，转移出去概率0.4，皮到卡是0.5，所以皮到卡是`0.4*0.5 = 0.2`；皮到丘是`0.4*0.3 = 0.12`；

#### 连续语音识别：
对于待识别语音（很多单词），只需要在大的复合模型上走，一边走一边和待识别语音匹配，匹配过程就是计算状态观测概率的过程。最匹配的就是最佳路径。可用viterbi解码解决。有了最佳路径之后，看最佳路径上经过了哪些单词的声学模型，把单词串起来，就是一句话的识别结果。

### 大词汇量语音识别 
当词汇量大时，为每个单词训练HMM不现实。（因为每个单词的模型是对这个单词录很多次音来训练出来的），所以不能以单词为单位训练HMM，而要用更小的单位：音素

两步：音素HMM拼接成单词HMM（用词典拼），单词HMM复合成语言HMM。HCLG：H:HMM C:上下文 L:词典 G:gram语言模型

得到大规模模型后，这个模型怎样进行训练和解码？：
 - 训练
   - 给定许多语音和对应的音素串，求模型参数
   - 每个音素串的HMM是单向的，仍用EM算法。 每句话的音素串已知，所以模型还是单向的，不需要知道语言模型。所以训练过程和之前一样的（EM算法），即先瞎猜一个对齐，比如均匀分割，由它求出模型参数，用模型参数来更新对齐方式，由对齐方式再更新模型参数，这样迭代到收敛。
 - 解码
   - 给定一门语言的HMM（包括语言模型、词典、声学模型）和一条语音，求单词串。
   - （在刚才那个巨大的图中）用Viterbi算法求最佳路径（beam search剪枝（因为路径有太多了））：用状态得到特征向量，得到特征向量最大概率。beam：每条路径和当前最好路径的差别，如果这条路径离最好的概率相差太大，就放弃这条路径，就剪枝。
   - 最佳路径经过的单词为识别结果（也可以得到n-best list或lattice）

