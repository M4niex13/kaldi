#!/bin/env python

# Copyright 2016  Vimal Manohar
# Apache 2.0

from __future__ import print_function
import sys, operator, argparse
import random

# Segment data using CTM and the edits from Levenshtein alignment of 'hypothesis' and 'reference':
# (i.e. the output of 'align-text' post-processed by 'wer_per_utt_details.pl')
# This takes as input the file generated by the script
# steps/cleanup/append_eval_to_ctm.py

# The information added to each token in the CTM is the reference word and one
# of the following labels:
#  'C' = correct
#  'S' = substitution
#  'D' = deletion
#  'I' = insertion
#  'SC' = silence and neighboring hypothesis words are both correct
#  'SS' = silence and one of the neighboring hypothesis words is a substitution
#  'SD' = silence and one of the neighboring hypothesis words is a deletion
#  'SI' = silence and one of the neighboring hypothesis words is an insertion
#  'XS' = reference word substituted by the OOV symbol in the hypothesis and both the neighboring hypothesis words are correct
# The priority order for the silence labels is 'SD' > 'SS' > 'SI'.

# Note: Additional lines are added to the CTM to account for deletions.

# Input file:
# <file-id> <channel> <start-time> <end-time> <conf> <hyp-word> <ref-word> <edit>

## TimBrown_2008P-0007226-0007620 1 0.00 0.10 when <eps> I
## TimBrown_2008P-0007226-0007620 1 0.10 0.09 i <eps> I
## TimBrown_2008P-0007226-0007620 1 0.19 0.30 some [NOISE] S
## TimBrown_2008P-0007226-0007620 1 0.49 0.11 when when C
## TimBrown_2008P-0007226-0007620 1 0.60 0.06 i i C
## TimBrown_2008P-0007226-0007620 1 0.66 0.19 say say C
## TimBrown_2008P-0007226-0007620 1 0.84 0.45 go go C
## TimBrown_2008P-0007226-0007620 1 1.30 0.31 [COUGH] [COUGH] C
## TimBrown_2008P-0007226-0007620 1 1.61 0.13 you you C
## TimBrown_2008P-0007226-0007620 1 1.74 0.00 <eps> [COUGH] D
## TimBrown_2008P-0007226-0007620 1 1.74 0.00 <eps> a D
## TimBrown_2008P-0007226-0007620 1 1.74 0.00 <eps> ve D
## TimBrown_2008P-0007226-0007620 1 1.74 0.18 got got C
## TimBrown_2008P-0007226-0007620 1 1.92 0.37 thirty thirty C
## TimBrown_2008P-0007226-0007620 1 2.29 0.83 seconds seconds C
## TimBrown_2008P-0007226-0007620 1 3.12 0.33 <eps> <eps> SC
## TimBrown_2008P-0007226-0007620 1 3.45 0.04 [BREATH] [BREATH] C
## TimBrown_2008P-0007226-0007620 1 3.49 0.11 to to C
## TimBrown_2008P-0007226-0007620 1 3.60 0.32 [NOISE] [NOISE] C


def enum(*sequential, **named):
    enums = dict(zip(sequential, range(len(sequential))), **named)
    reverse = dict((value, key) for key, value in enums.iteritems())
    enums['reverse_mapping'] = reverse
    return type('Enum', (), enums)

def GetArgs():
    parser = argparse.ArgumentParser(description =
        """Segment data using CTM and the Levenshtein alignment of 'hypothesis' and 'reference':
        (i.e. the output of 'align-text' post-processed by 'wer_per_utt_details.pl')""",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter)

    parser.add_argument("--silence-symbol", default = "<eps>",
                        help = "Must be provided to ignore silence words in the "
                        "CTM that would be present if --print-silence was true in "
                        "nbest-to-ctm binary")
    parser.add_argument("--oov-symbol", default = "<unk>",
                        help = "Substitutions by oov are treated specially")
    parser.add_argument("--frame-shift", type = float, default = 10,
                        help = "Frame shift in milliseconds")
    parser.add_argument("--max-segment-length", type = int, default = 1000,
                        help = "Maximum length of segment allowed in number of frames.")
    parser.add_argument("--max-silence-length", type = int, default = 50,
                        help = """Maximum length of silence that is allowed within segments.
                        If the length of silence is larger than this, it is
                        removed and the segment is split""")
    parser.add_argument("--max-incorrect-words", type = int, default = 0,
                        help = "Maximum number of incorrect words that will be included per segment")
    parser.add_argument("--min-correct-frames", type = int, default = 0,
                        help = "If the number of correct frames in the "
                        "created subsegment is below this value, "
                        "remove it")
    parser.add_argument("--min-length-for-adding-unk", type = int, default = 5,
                        help = "Add an <unk> if there are more than this many frames of a partial word")
    parser.add_argument("--max-utterance-wer", type = float, default = 20000,
                        help = "Maximum WER%% of utterance that will be "
                        "considered for cleanup. "
                        "If WER%% is above this, the segment is completely removed")
    parser.add_argument("--pad-length", type = int, default = 5,
                        help = "Pad boundaries of the created subsegments by this many frames")
    parser.add_argument("--min-wer-for-splitting", type = float, default = -1,
                        help = "Do not split segments that have WER%% lower than this value. "
                        "Note: The silence that is longer than max-silence-length will be removed before this step")
    parser.add_argument("--length-tolerance", type = int, default = 2,
                        help = "Tolerance while merging segments")
    parser.add_argument("--silence-padding-incorrect", type = int, default = 20,
                        help = """Maximum number of silence frames to pad if the
                                    silence is near incorrect segment""")
    parser.add_argument("--silence-padding-correct", type = int, default = 5,
                        help = """Maximum number of silence frames to pad if the
                                    silence is near correct segments""")
    parser.add_argument("--min-silence-padding", type = int, default = 5,
                        help = """Minimum number of silence frames to pad
                                segments by""")
    parser.add_argument("--seed", type = int, default = 0,
                        help = "Seed for random number generator")

    # Required arguments
    parser.add_argument("ctm_eval",
                        help = "CTM appended with word-edit information. ")
    parser.add_argument("segments_out", metavar = "<segments-out>",
                        help = "Output sub-segments")
    parser.add_argument("text_out", metavar = "<text-out>",
                        help = "Output sub-segment text")
    args = parser.parse_args()

    return args

def CheckArgs(args):
    args.config = argparse.Namespace()

    args.config.silence_symbol = args.silence_symbol
    args.config.oov_symbol = args.oov_symbol
    args.config.max_utterance_wer = args.max_utterance_wer
    args.config.max_silence_length = args.max_silence_length
    args.config.max_segment_length = args.max_segment_length
    args.config.min_correct_frames = args.min_correct_frames
    args.config.min_wer_for_splitting = args.min_wer_for_splitting
    args.config.min_length_for_adding_unk = args.min_length_for_adding_unk
    args.config.max_incorrect_words = args.max_incorrect_words
    args.config.pad_length = args.pad_length
    args.config.frame_shift = args.frame_shift
    args.config.length_tolerance = args.length_tolerance
    args.config.silence_padding_correct = args.silence_padding_correct
    args.config.silence_padding_incorrect = args.silence_padding_incorrect
    args.config.min_silence_padding = args.min_silence_padding

    return args

kSilenceEdits = ['D', 'SC', 'SS', 'SD', 'SI']

class CtmEvalProcessor:
    def __init__(self, args):
        self.config = args.config

        self.segments_out_handle = open(args.segments_out, 'w')
        self.text_out_handle = open(args.text_out, 'w')

        self.segments_out = args.segments_out
        self.text_out = args.text_out

        self.ctm_eval = dict()      # key is the utt-id

        # Some statistics for debugging
        self.stats = argparse.Namespace()

        self.stats.num_merged = 0       # Total number of created segments that
                                        # are merged because they are within
                                        # length_tolerance distance
        self.stats.num_padded_frames = 0      # Total number of padded frames
        self.stats.num_oov_symbols_added = 0  # Total number of oov symbols added
                                              # in the padded regions to account
                                              # for partial words

        # Total number of segments processed due to various options
        self.stats.segments_ignored_on_max_utterance_wer = 0
        self.stats.segments_ignored_on_min_correct_frames = 0
        self.stats.segments_ignored_on_max_incorrect_words = 0
        self.stats.segments_split_on_max_silence_length = 0
        self.stats.segments_not_splitting = 0     # Total number of segments not split due to min_wer_for_splitting

    def LoadCtmEval(self, ctm_eval_in):
        # Load the ctm with edits appended into a dictionary
        ctm_eval = self.ctm_eval

        with open(ctm_eval_in, 'r') as f:
            for l in f:
                splits = l.strip().split()
                splits[2] = int(float(splits[2]) / self.config.frame_shift * 1000 + 0.0001)    # begin time
                splits[3] = int(float(splits[3]) / self.config.frame_shift * 1000 + 0.5)      # duration

                if len(splits) == 8:
                    splits[5] = float(splits[5])    # confidence
                elif len(splits) != 7:
                    raise Exception("Invalid line in ctm-eval {0}".format(l))

                utt = splits[0]
                ctm_eval.setdefault(utt, []).append(tuple(splits))

    # Counts the number of word errors for each token in the processed CTM
    # starting from seg_start to seg_end
    def GetRunningWordErrors(self, utt_ctm_eval, seg_start, seg_end):
        num_word_errors = 0
        num_words = 0
        running_word_errors = []
        for i in range(seg_start, seg_end):
            if (utt_ctm_eval[i][-1] in ['D','I','S']):
                num_word_errors += 1
            if (utt_ctm_eval[i][-2] != self.config.silence_symbol):
                num_words += 1
            running_word_errors.append((float(num_word_errors),
                float(num_words)))
        return running_word_errors

    # Print segments and corresponding text
    def PrintSegments(self, utt, segments):
        for n in range(0, len(segments)):
            beg,end,text = segments[n]
            utt_id = "%s-%06d-%06d" % (utt, beg, end)
            beg = float(beg) * self.config.frame_shift / 1000
            end = float(end) * self.config.frame_shift / 1000
            self.segments_out_handle.write('%s %s %.02f %.02f\n' % (utt_id, utt,
                beg, end))
            self.text_out_handle.write('%s %s\n' % (utt_id, text))

    # Find the transcript for a segment from the processed CTM.
    # If the segment (usually the case after padding) does not entirely
    # cover a word token from the processed CTM, an OOV symbol can be added.
    # This is done only if there is at least min_length_for_adding_unk frames
    # of the word token that is covered by the segment.
    def AddTextToSegments(self, utt, segments, frames_to_include):
        utt_ctm_eval = self.ctm_eval[utt]

        i = 0

        for n in range(0, len(segments)):
            beg,end = segments[n]   # Frame indices
            text_for_seg = ""

            # word1     word2    word3     word4 ......... wordN
            #          beg                    end
            #                      i

            while i > 0 and utt_ctm_eval[i][2] > beg:
                i -= 1

            # word1     word2    word3     word4 ......... wordN
            #          beg                    end
            #   i

            while sum(utt_ctm_eval[i][2:4]) <= beg:
                i += 1

            # word1     word2    word3     word4 ......... wordN
            #          beg                    end
            #             i

            if (utt_ctm_eval[i][2] < beg and
                    utt_ctm_eval[i][-1] not in ['SC','SD','SS','SI','I']):
                beg = max(0, min(utt_ctm_eval[i][2] - self.config.min_length_for_adding_unk, beg))
                self.stats.num_oov_symbols_added += 1
                text_for_seg = self.config.oov_symbol

            num_nonsil_words = 0

            # word1     word2    word3     word4 ......... wordN
            #          beg                    end
            #                                     i
            while i < len(utt_ctm_eval) and sum(utt_ctm_eval[i][2:4]) < end:
                if utt_ctm_eval[i][-2] != self.config.silence_symbol:
                    text_for_seg += " " + utt_ctm_eval[i][-2]
                    num_nonsil_words += 1
                i += 1

            if (i < len(utt_ctm_eval) and utt_ctm_eval[i][2] < end and
                    utt_ctm_eval[i][-1] not in ['SC','SD','SS','SI','I']):
                end = min(sum(utt_ctm_eval[-1][2:4]), max(utt_ctm_eval[i][2] + self.config.min_length_for_adding_unk, end))
                self.stats.num_oov_symbols_added += 1
                text_for_seg += " " + self.config.oov_symbol

            if num_nonsil_words == 0:
                text_for_seg = None

            segments[n] = (beg,end,text_for_seg)

    # Pad segments by a few frames on either side.
    # TODO: Find a smarter way of padding when there is no silence.
    def PadSegments(self, utt, segments):
        i = 0
        utt_ctm_eval = self.ctm_eval[utt]
        while i < len(segments):
            beg,end = segments[i]
            beg = max(beg - self.config.pad_length, 0)
            end = end + self.config.pad_length
            self.stats.num_padded_frames += beg - segments[i][0] + end - segments[i][1]
            segments[i] = (beg, end)
            i += 1

    # If the created segments overlap or are close together (only a
    # length_threshold frames from end of segment to beginning of next segment),
    # then they are merged into a single segments.
    def MergeSegments(self, segments):
        i = 1
        while i < len(segments):
            beg,end = segments[i]
            if (segments[i-1][1] > beg - self.config.length_tolerance and
                end - segments[i-1][0] < self.config.max_segment_length):
                segments[i-1] = (segments[i-1][0], max(segments[i-1][1],end))
                segments.pop(i)
                self.stats.num_merged += 1
            else:
                i += 1

    def CreateSegments(self, utt_ctm_eval, utt, seg_start,
                       seg_end, frames_to_add_left, frames_to_add_right):
        # Compute start and end frames corresponding to the segment under
        # consideration
        start_frame = utt_ctm_eval[seg_start][2]
        end_frame = utt_ctm_eval[seg_end-1][2] + utt_ctm_eval[seg_end-1][3] + 1
        # + 1 here is because the last one is ignored in python ranges

        # Count the number of frames that are correct or are substitutions by
        # <unk>
        frames_to_include = [ 0 for x in range(0, end_frame) ]
        for i in range(seg_start, seg_end):
            if utt_ctm_eval[i][-1] in ['C','XS']:
                for x in range(utt_ctm_eval[i][2], sum(utt_ctm_eval[i][2:4]) + 1):
                    frames_to_include[x] = 1
            if utt_ctm_eval[i][-1] in kSilenceEdits:
                for x in range(utt_ctm_eval[i][2], sum(utt_ctm_eval[i][2:4]) + 1):
                    frames_to_include[x] = 2

        num_frames_correct = sum([ 1 for x in frames_to_include if x == 1])

        # If we do not have enough number of correct frames, we will just ignore
        # this segment
        if num_frames_correct < self.config.min_correct_frames:
            self.stats.segments_ignored_on_min_correct_frames += 1
            return 0

        # Count the number of word errors in this segment
        running_word_errors = self.GetRunningWordErrors(utt_ctm_eval,
                                                        seg_start, seg_end)

        # If the WER for this segment > max_utterance_wer allowed then, we will
        # ignore this segment
        if (float(running_word_errors[-1][0]) /
                  running_word_errors[-1][1] * 100 > self.config.max_utterance_wer):
            self.stats.segments_ignored_on_max_utterance_wer += 1
            return 0

        # If the WER for this segment is < min_wer_for_splitting, then do not
        # split this segment and take the full segments.
        # Otherwise, we split it at silence or incorrect words.
        if (float(running_word_errors[-1][0]) /
                running_word_errors[-1][1] * 100 < self.config.min_wer_for_splitting):
            self.stats.segments_not_splitting += 1
            for n in range(start_frame, end_frame):
                frames_to_include[n] = 1
        else:
            incorrect_start = -1
            incorrect_end = -1

            i = seg_start
            while i < seg_end:
                # Find beginning of split point
                if (incorrect_start == -1
                    and utt_ctm_eval[i][-1] not in ['C','XS']):
                    incorrect_start = i

                # Find end of split point
                if (incorrect_start >= 0 and utt_ctm_eval[i][-1] in ['C','XS']):
                    if (running_word_errors[i-seg_start][0] -
                        running_word_errors[incorrect_start-seg_start][0] >
                        self.config.max_incorrect_words):
                        # Number of word errors is larger than max_incorrect_words.
                        # So this region is not included in the segments.
                        self.stats.segments_ignored_on_max_incorrect_words += 1

                        # Add some padding
                        if incorrect_start > 0:     # Ignore the boundary
                            if utt_ctm_eval[incorrect_start][-1] == 'SC':
                                right_padding = min(self.config.silence_padding_correct, utt_ctm_eval[incorrect_start][3])
                                if right_padding > self.config.min_silence_padding:
                                    right_padding = random.randint(self.config.min_silence_padding, right_padding)
                            elif utt_ctm_eval[incorrect_start][-1] in kSilenceEdits:
                                right_padding = min(self.config.silence_padding_incorrect, utt_ctm_eval[incorrect_start][3])
                                if right_padding > self.config.min_silence_padding:
                                    right_padding = random.randint(self.config.min_silence_padding, right_padding)
                            else:
                                right_padding = 0

                            for n in range(utt_ctm_eval[incorrect_start][2], utt_ctm_eval[incorrect_start][2] + right_padding):
                                frames_to_include[n] = 1

                        if i > 0:                   # Ignore the boundary
                            if utt_ctm_eval[i-1][-1] == 'SC':
                                left_padding = min(self.config.silence_padding_correct, utt_ctm_eval[i-1][3])
                                if left_padding > self.config.min_silence_padding:
                                    left_padding = random.randint(self.config.min_silence_padding, left_padding)
                            elif utt_ctm_eval[i-1][-1] in kSilenceEdits:
                                left_padding = min(self.config.silence_padding_incorrect, utt_ctm_eval[i-1][3])
                                if left_padding > self.config.min_silence_padding:
                                    left_padding = random.randint(self.config.min_silence_padding, left_padding)
                            else:
                                left_padding = 0

                            for n in range(utt_ctm_eval[i][2] - left_padding, utt_ctm_eval[i][2]):
                                frames_to_include[n] = 1

                        incorrect_start = -1
                    else:
                        # Incorrectly-recognized-words-region that is included
                        # because it has less than max_incorrect_words
                        # word errors
                        for n in range(utt_ctm_eval[incorrect_start][2],
                                       sum(utt_ctm_eval[i-1][2:4]) + 1):
                            frames_to_include[n] = 3

                        incorrect_start = -1
                i += 1

            if incorrect_start >= 0:
                if (running_word_errors[-1][0] -
                    running_word_errors[incorrect_start-seg_start][0] <=
                    self.config.max_incorrect_words):
                    # Incorrectly-recognized-words-region that is included
                    # because it has less than max_incorrect_words
                    # word errors
                    for n in range(utt_ctm_eval[incorrect_start][2],
                                   sum(utt_ctm_eval[seg_end-1][2:4]) + 1):
                        frames_to_include[n] = 3
                else:
                    self.stats.segments_ignored_on_max_incorrect_words += 1

        if frames_to_include[start_frame] in [1,3]:
            for n in range(start_frame - frames_to_add_left, start_frame):
                frames_to_include[n] = 1
        if end_frame > 0 and frames_to_include[end_frame-1] in [1,3]:
            frames_to_include.extend([1 for n in range(end_frame,  end_frame + frames_to_add_right)])

        segments = self.IncludeFramesInSegments(frames_to_include)

        if self.config.pad_length > 0:
            segments.sort(key = lambda x:(x[0],x[1])) # Sort by 'beg' time,
            self.PadSegments(utt, segments)

        segments.sort(key = lambda x:(x[0],x[1])) # Sort by 'beg' time,
        self.MergeSegments(segments)

        self.AddTextToSegments(utt, segments, frames_to_include)

        self.PrintSegments(utt, segments)

        return len(segments)

    # Create the segments using frame-level information.
    # A segment is added starting from a region that has correctly recognized words
    # words or less than a certain number of incorrect words.
    # A segment ends at the beginning of an incorrect-words-region (See
    # CreateSegments function).
    def IncludeFramesInSegments(self, frames_to_include):
        segments = []
        n = 0
        new_seg_start = -1
        while n < len(frames_to_include):
            if new_seg_start == -1 and frames_to_include[n] in [1,3]:
                new_seg_start = n

            # TODO: Add the pad segments part here
            if new_seg_start >= 0 and frames_to_include[n] in [0,2]:
                # End segment at the start of an incorrect region
                segments.append((new_seg_start, n))
                new_seg_start = -1
            n += 1

        if new_seg_start >= 0:
            segments.append((new_seg_start, len(frames_to_include)))

        return segments

    # The upper-level function that does segmentation for an utterance
    # and prints out the segments and the corresponding transcript
    def SegmentUtterance(self, utt):
        utt_ctm_eval = self.ctm_eval[utt]
        utt_ctm_eval.sort(key = lambda x:(x[2],x[2]+x[3])) # Sort by 'beg' time,

        seg_start = 0
        i = 0
        num_segments = 0

        frames_to_add_left = 0
        frames_to_add_right = 0

        while i < len(utt_ctm_eval):
            if (utt_ctm_eval[i][-1] == 'SC' and
                utt_ctm_eval[i][3] > self.config.max_silence_length):
                # Remove long silence regions that have correct words
                # on both sides.

                frames_to_add_right = min(self.config.silence_padding_correct, utt_ctm_eval[i][3])
                if frames_to_add_right > self.config.min_silence_padding:
                    random.randint(self.config.min_silence_padding, frames_to_add_right)

                if (seg_start < i):
                    num_segments += self.CreateSegments( utt_ctm_eval, utt,
                            seg_start, i,
                            frames_to_add_left, frames_to_add_right)
                    self.stats.segments_split_on_max_silence_length += 1

                frames_to_add_left = random.randint(self.config.min_silence_padding, min(self.config.silence_padding_correct, utt_ctm_eval[i][3]))
                if frames_to_add_left > self.config.min_silence_padding:
                    random.randint(self.config.min_silence_padding, frames_to_add_left)

                seg_start = i + 1
            i += 1
        if seg_start < len(utt_ctm_eval):
            num_segments += self.CreateSegments( utt_ctm_eval, utt, seg_start,
                                                 len(utt_ctm_eval),
                                                 frames_to_add_left, 0)

    def ProcessCtmEvalForUtt(self, utt):
        utt_ctm_eval = self.ctm_eval[utt]
        utt_ctm_eval.sort(key = lambda x:(x[2],x[2]+x[3])) # Sort by 'beg' time,
        self.SegmentUtterance(utt)

    def PrintStats(self, f):
        print ("num segments merged %d" % self.stats.num_merged, file = f)
        print ("num padded frames = %d" % self.stats.num_padded_frames, file = f)
        print ("num oov symbols added = %d" % self.stats.num_oov_symbols_added, file = f)
        print ("segments ignored on max_utterance_wer = %d" % self.stats.segments_ignored_on_max_utterance_wer, file = f)
        print ("segments not splitting  = %d" % self.stats.segments_not_splitting, file = f)
        print ("segments ignored on min_correct_frames = %d" % self.stats.segments_ignored_on_min_correct_frames, file = f)
        print ("segments ignored on max_incorrect_words = %d" % self.stats.segments_ignored_on_max_incorrect_words, file = f)
        print ("segments split on max_silence_length = %d" % self.stats.segments_split_on_max_silence_length, file = f)


def Main():
    print(" ".join(sys.argv), file = sys.stderr)

    args = GetArgs();
    args = CheckArgs(args)

    random.seed(args.seed)

    ctm_eval_processor = CtmEvalProcessor(args)
    ctm_eval_processor.LoadCtmEval(args.ctm_eval)

    for utt in sorted(ctm_eval_processor.ctm_eval.keys()):
        ctm_eval_processor.ProcessCtmEvalForUtt(utt)

    ctm_eval_processor.PrintStats(sys.stderr)

if __name__ == "__main__":
    Main()

