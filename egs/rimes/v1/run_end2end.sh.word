#!/bin/bash

# Copyright 2018    Hossein Hadian
#                   Ashish Arora
#                   Jonathan Chang
# Apache 2.0

set -e
stage=0
nj=50
overwrite=false
rimes_database=/export/corpora5/handwriting_ocr/RIMES
train_set=train
use_extra_corpus_text=false
. ./cmd.sh ## You'll want to change cmd.sh to something that will work on your system.
           ## This relates to the queue.
. ./path.sh
. ./utils/parse_options.sh  # e.g. this parses the above options
                            # if supplied.

if [ $stage -le 0 ]; then
  if [ -f data/train/text ] && ! $overwrite; then
    echo "$0: Not processing, probably script have run from wrong stage"
    echo "Exiting with status 1 to avoid data corruption"
    exit 1;
  fi

  echo "$0: Preparing data..."
  local/prepare_data.sh --download-dir "$rimes_database" \
    --use_extra_corpus_text false

fi

mkdir -p data/{train,test,val}/data
if [ $stage -le 1 ]; then
  echo "$(date) stage 1: getting allowed image widths for e2e training..."
  image/get_image2num_frames.py --feat-dim 40 data/train
  image/get_allowed_lengths.py --frame-subsampling-factor 4 10 data/train
  echo "$(date) Extracting features, creating feats.scp file"
  for set in train test val; do
    local/extract_features.sh --nj $nj --cmd "$cmd" data/${set}
    steps/compute_cmvn_stats.sh data/${set} || exit 1;
  done
  utils/fix_data_dir.sh data/train
fi

if [ $stage -le 3 ]; then
  echo "$0: Preparing dictionary and lang..."
  local/prepare_dict.sh --dir data/local/dict --build_bpe_based_dict false
  utils/prepare_lang.sh --num-sil-states 4 --num-nonsil-states 8 --sil-prob 0.9999 \
                        data/local/dict "<unk>" data/lang_train/temp data/lang_train
  silphonelist=`cat data/lang_train/phones/silence.csl`
  nonsilphonelist=`cat data/lang_train/phones/nonsilence.csl`
  local/word/gen_topo.py 8 4 4 $nonsilphonelist $silphonelist data/lang_train/phones.txt >data/lang_train/topo

  local/word/train_lm.sh.word
  utils/format_lm.sh data/lang_train data/local/local_lm/data/arpa/3gram_unpruned.arpa.gz \
                     data/local/dict/lexicon.txt data/lang_train

  echo "$0: Preparing the unk model for open-vocab decoding..."
  utils/lang/make_unk_lm.sh --ngram-order 4 --num-extra-ngrams 7500 \
                            data/local/dict exp/unk_lang_model
  utils/prepare_lang.sh --unk-fst exp/unk_lang_model/unk_fst.txt \
                        data/local/dict "<unk>" data/lang/temp data/lang
  silphonelist=`cat data/lang/phones/silence.csl`
  nonsilphonelist=`cat data/lang/phones/nonsilence.csl`
  local/word/gen_topo.py 8 4 4 $nonsilphonelist $silphonelist data/lang/phones.txt >data/lang/topo
  cp data/lang_train/G.fst data/lang/G.fst
fi

if [ $stage -le 4 ]; then
  echo "$0: Calling the flat-start chain recipe..."
  local/chain/run_e2e_cnn.sh --train_set $train_set
fi

if [ $stage -le 5 ]; then
  echo "$0: Aligning the training data using the e2e chain model..."
  steps/nnet3/align.sh --nj 50 --cmd "$cmd" \
                       --scale-opts '--transition-scale=1.0 --self-loop-scale=1.0 --acoustic-scale=1.0' \
                       data/$train_set data/lang exp/chain/e2e_cnn_1a exp/chain/e2e_ali_train
fi

if [ $stage -le 6 ]; then
  echo "$0: Building a tree and training a regular chain model using the e2e alignments..."
  local/chain/run_cnn_e2eali.sh --train_set $train_set
fi
